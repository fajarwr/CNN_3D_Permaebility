{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_3D_Permeability.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fajarwr/CNN_3D_Permaebility/blob/branch_02/CNN_3D_Permeability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "uZ46QlYesJ-5",
        "colab_type": "code",
        "outputId": "9cd7c10c-fcc1-41f0-c4f0-1bd1540d8e8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import division, print_function, absolute_import\n",
        "from keras.models import Sequential, model_from_json\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv3D, MaxPooling3D, BatchNormalization, Input\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import ReduceLROnPlateau, TensorBoard\n",
        "import h5py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('white')\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, r2_score\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "SnAA9PTBwMmF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Define r square matric\n",
        "def r2_keras(y_true, y_pred):\n",
        "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
        "    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
        "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_MXt2sDLxbiZ",
        "colab_type": "code",
        "outputId": "e25d5dd4-e5df-44e7-f714-56ae78cb241b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MLiVBMLc46FL",
        "colab_type": "code",
        "outputId": "1321d852-1d9a-41de-bf30-d25195510645",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cd /content"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IS2krkmz4_QN",
        "colab_type": "code",
        "outputId": "58cfa8c3-195c-4b97-e2d1-5edfc78c530c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "8XaqCiE4yCyP",
        "colab_type": "code",
        "outputId": "30c87543-788b-49ff-b502-bfe24c42dfde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ha4Mgecc-J0d",
        "colab_type": "code",
        "outputId": "1fcbde23-b4d4-4424-9d94-4e8ab93e6cd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mgdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "glOQgwXky21u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('gdrive/My Drive/CNN_Permeability/001_PythonCodes/CNN_3D_Permaebility')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vJSPpJRz5tQ7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Import datagenerator taken from \n",
        "#https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
        "from DataGenerator_3D_Classes import DataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0j0cYATd5_Ke",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Experiment number\n",
        "exp_num = 17\n",
        "os.chdir('../../005_Result/CNN_3D')\n",
        "if any('00'+str(exp_num) in s for s in os.listdir(os.getcwd())):\n",
        "    sys.exit('Alert : There is already 00'+str(exp_num)+' experiment result!!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kwENhDxO7VRN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Load the data\n",
        "dim1,dim2,dim3,chn = 100,100,100,1\n",
        "training_len = 90\n",
        "testing_len = 10\n",
        "total_len = training_len + testing_len\n",
        "phi = []\n",
        "ssa = []\n",
        "os.chdir('../../002_Data/Berea_Sandstone_npy')\n",
        "for image3D_npy in os.listdir(os.getcwd())[:total_len]:\n",
        "    phi.append([float(s) for s in re.findall('[-+]?\\d*\\.\\d+|\\d+',\n",
        "                image3D_npy)][1])\n",
        "    ssa.append([float(s) for s in re.findall('[-+]?\\d*\\.\\d+|\\d+',\n",
        "                image3D_npy)][2])\n",
        "k = np.power(1-np.array(phi), 3)/np.power(ssa, 2)\n",
        "k_norm = k/np.max(k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vmKNGGhf7lFj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "params = {'dim': (dim1,dim2,dim3),\n",
        "          'batch_size': 20,\n",
        "          'n_classes': 1,\n",
        "          'n_channels': chn,\n",
        "          'shuffle': False}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GpwZ-XK4_ebe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Datasets\n",
        "partition = {\n",
        "\t\t'train': os.listdir(os.getcwd())[:training_len],\n",
        "\t\t'validation': os.listdir(os.getcwd())[training_len:total_len],\n",
        "        'total' : os.listdir(os.getcwd())[:total_len]\n",
        "\t\t}\n",
        "labels = dict(zip(os.listdir(os.getcwd())[:total_len], k_norm))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ym1wn7f2_h7D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generators\n",
        "training_generator = DataGenerator(partition['train'], labels, **params)\n",
        "validation_generator = DataGenerator(partition['validation'], labels, **params)\n",
        "total_generator = DataGenerator(partition['total'], labels, **params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z1SuLY-E_mmB",
        "colab_type": "code",
        "outputId": "df3081d8-bcc9-4e72-85b5-cdc7cab0b06f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "#Define a model\n",
        "model = Sequential()\n",
        "model.add(Conv3D(32, kernel_size=5, strides=(2, 2, 2), padding='valid',\n",
        "                 data_format='channels_last', dilation_rate=(1, 1, 1),\n",
        "                 activation='relu', use_bias=True,\n",
        "                 kernel_initializer='glorot_uniform', bias_initializer='zeros',\n",
        "                 kernel_regularizer=None, bias_regularizer=None, \n",
        "                 activity_regularizer=None, kernel_constraint=None,\n",
        "                 bias_constraint=None, input_shape=(dim1, dim2, dim3, chn)))\n",
        "model.add(Conv3D(32, kernel_size=5, strides=(2, 2, 2), padding='valid',\n",
        "                 data_format='channels_last', dilation_rate=(1, 1, 1),\n",
        "                 activation='relu', use_bias=True,\n",
        "                 kernel_initializer='glorot_uniform', bias_initializer='zeros',\n",
        "                 kernel_regularizer=None, bias_regularizer=None, \n",
        "                 activity_regularizer=None, kernel_constraint=None,\n",
        "                 bias_constraint=None))\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(1, 1, 1), padding='valid',\n",
        "                       data_format='channels_last'))\n",
        "model.add(Conv3D(32, kernel_size=5, strides=(2, 2, 2), padding='valid',\n",
        "                 data_format='channels_last', dilation_rate=(1, 1, 1),\n",
        "                 activation='relu', use_bias=True,\n",
        "                 kernel_initializer='glorot_uniform', bias_initializer='zeros',\n",
        "                 kernel_regularizer=None, bias_regularizer=None, \n",
        "                 activity_regularizer=None, kernel_constraint=None,\n",
        "                 bias_constraint=None))\n",
        "model.add(Conv3D(32, kernel_size=5, strides=(2, 2, 2), padding='valid',\n",
        "                 data_format='channels_last', dilation_rate=(1, 1, 1),\n",
        "                 activation='relu', use_bias=True,\n",
        "                 kernel_initializer='glorot_uniform', bias_initializer='zeros',\n",
        "                 kernel_regularizer=None, bias_regularizer=None, \n",
        "                 activity_regularizer=None, kernel_constraint=None,\n",
        "                 bias_constraint=None))\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(1, 1, 1), padding='valid',\n",
        "                       data_format='channels_last'))\n",
        "model.add(Flatten(data_format='channels_last'))\n",
        "model.add(Dense(128, activation='relu', use_bias=True,\n",
        "                kernel_initializer='glorot_uniform', bias_initializer='zeros',\n",
        "                kernel_regularizer=None, bias_regularizer=None,\n",
        "                activity_regularizer=None, kernel_constraint=None,\n",
        "                bias_constraint=None))\n",
        "model.add(Dense(128, activation='relu', use_bias=True,\n",
        "                kernel_initializer='glorot_uniform', bias_initializer='zeros',\n",
        "                kernel_regularizer=None, bias_regularizer=None,\n",
        "                activity_regularizer=None, kernel_constraint=None,\n",
        "                bias_constraint=None))\n",
        "model.add(Dense(64, activation='relu', use_bias=True,\n",
        "                kernel_initializer='glorot_uniform', bias_initializer='zeros',\n",
        "                kernel_regularizer=None, bias_regularizer=None,\n",
        "                activity_regularizer=None, kernel_constraint=None,\n",
        "                bias_constraint=None))\n",
        "model.add(Dense(1, activation=None, use_bias=True,\n",
        "                kernel_initializer='glorot_uniform', bias_initializer='zeros',\n",
        "                kernel_regularizer=None, bias_regularizer=None,\n",
        "                activity_regularizer=None, kernel_constraint=None,\n",
        "                bias_constraint=None))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z2eeTh_c_xEZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Compile the model\n",
        "model.compile(optimizer='Adam', loss='mean_squared_error', metrics=[r2_keras],\n",
        "              loss_weights=None, sample_weight_mode=None,weighted_metrics=None,\n",
        "              target_tensors=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NhaIBZ5f_0oI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#This checkpoint object will store the model parameters in the file \"weights.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath='../../../../../Weights_CNN3D_00'+str(exp_num)+'.hdf5', monitor='val_loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bNaaS6qM_-HY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Change to data directory\n",
        "os.chdir('../../002_Data/Berea_Sandstone_npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "46vli8axAMIH",
        "colab_type": "code",
        "outputId": "bd0f2bd9-fc9c-4703-82cc-aefc6ee62e6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "# Train model on dataset\n",
        "history = model.fit_generator(generator=training_generator, epochs=20,\n",
        "                    callbacks=[checkpoint], workers=1, use_multiprocessing=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0CZxZi4xBo_S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Save history\n",
        "history_df = pd.DataFrame.from_dict(history.history)\n",
        "history_df.to_excel('../../005_Result/CNN_3D/History_CNN3D_00'+str(exp_num)+'.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pQBAQ7FhBwHO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Load the model and plot the data\n",
        "model.load_weights('../../../../../Weights_CNN3D_00'+str(exp_num)+'.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d5cnuj1yB1zb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Store the training & testing result\n",
        "total_result = model.predict_generator(generator=total_generator, steps=None,\n",
        "                                  max_queue_size=10, workers=1,\n",
        "                                  use_multiprocessing=False, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yb4O1gg4CEo-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Save result\n",
        "training_result = {\n",
        "\t\t'true_training': np.reshape(k_norm[:training_len]*np.max(k),(training_len,)),\n",
        "\t\t'pred_training': np.reshape(total_result[:training_len]*np.max(k),(training_len,))\n",
        "\t\t}\n",
        "testing_result = {\n",
        "        'true_testing': np.reshape(k_norm[training_len:total_len]*np.max(k),(testing_len,)),\n",
        "\t\t'pred_testing': np.reshape(total_result[training_len:total_len]*np.max(k),(testing_len,))\n",
        "        }\n",
        "training_result_df = pd.DataFrame.from_dict(training_result)\n",
        "testing_result_df = pd.DataFrame.from_dict(testing_result)\n",
        "training_result_df.to_excel('../../005_Result/CNN_3D/Training_CNN3D_00'+\n",
        "                            str(exp_num)+'_'+str(r2_score (k_norm[:training_len]*np.max(k), total_result[:training_len]*np.max(k)))+'.xlsx')\n",
        "testing_result_df.to_excel('../../005_Result/CNN_3D/Testing_CNN3D_00'+\n",
        "                           str(exp_num)+'_'+str(r2_score(k_norm[training_len:total_len]*np.max(k), total_result[training_len:total_len]*np.max(k)))+'.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Coe39TF2CKyr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Plot the training data\n",
        "plt.figure()\n",
        "plt.scatter(np.arange(0,training_len),k_norm[:training_len]*np.max(k), label='$\\kappa$ true')\n",
        "plt.scatter(np.arange(0,training_len),total_result[:training_len]*np.max(k), label='$\\kappa$ pred')\n",
        "plt.title('Permeabilitas Kozeny Carman vs CNN Data Training')\n",
        "plt.xlabel('Subampel')\n",
        "plt.ylabel('$\\phi^3/ssa^2$')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hvJEopZHCQXe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Plot the testing data\n",
        "plt.figure()\n",
        "plt.scatter(np.arange(0,testing_len),k_norm[training_len:total_len]*np.max(k), label='$\\kappa$ true')\n",
        "plt.scatter(np.arange(0,testing_len),total_result[training_len:total_len]*np.max(k), label='$\\kappa$ pred')\n",
        "plt.title('Permeabilitas Kozeny Carman vs CNN Data Testing')\n",
        "plt.xlabel('Subsampel')\n",
        "plt.ylabel('$\\phi^3/ssa^2$')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N2zyhmq3CTOt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#PLot history MSE\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('PLot Nilai Mean Square Error untuk Setiap Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ldXKZcZCCVuD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Plot history r2_keras\n",
        "plt.figure()\n",
        "plt.plot(history.history['r2_keras'])\n",
        "plt.title('PLot Nilai $R^2$ untuk Setiap Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('$R^2$')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}